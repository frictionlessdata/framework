{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ecb2099",
   "metadata": {},
   "source": [
    "## Purpose\n",
    "To teach about using Frictionless to create a reproducible data workflow. You will start with a dataset that needs some more information, and will end with a data package that can be published!\n",
    "\n",
    "## Outline\n",
    "- Start by looking at the dataset & discussing the metadata. Are there things we need to change with the dataset?\n",
    "- Describe the data (infer metadata + a schema; edit the metadata + schema)\n",
    "- Extract (read in the dataset according to the schema)\n",
    "- Validate (check the data for errors)\n",
    "- Transform (clean the data)\n",
    "- Package (containerize the data + metadata/schema)\n",
    "\n",
    "## Resources\n",
    "- Dataset: https://figshare.com/articles/dataset/Portal_Project_Teaching_Database/1314459?file=10717186\n",
    "- Code documentation: https://framework.frictionlessdata.io/\n",
    "- Frictionless website: https://frictionlessdata.io/\n",
    "- Frictionless Slack if you want to join :-) https://frictionlessdata.slack.com/messages/general\n",
    "- Jupyter Notebook intro: https://datacarpentry.org/python-ecology-lesson/jupyter_notebooks/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ec3d45",
   "metadata": {},
   "source": [
    "So, what are we going to do today? We just saw how this dataset could be improved by having the metadata more machine readible & more easily accessible. We'll be packaging the data, doing some light cleaning, and then getting the data ready to publish! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1beb7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install frictionless"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8bd535",
   "metadata": {},
   "source": [
    "# Describe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405fb4b1",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "\n",
    "Let's start by looking at the dataset & discussing the metadata. Are there things we need to change with the dataset?\n",
    "\n",
    "(Everyone to open the data set to look at it). What kind of metadata is missing from this? (what info would we need to know to be able to use this data? eg units for weight, what does the species code mean? are there specific values for missing values? (note that the missing values are kind of interesting, but confusing))\n",
    "\n",
    "Can you find the metadata? https://esapubs.org/archive/ecol/E090/118/Portal_rodent_metadata.htm (Walk them through how I found the metadata from the software carpentries link, which has the data archive link (https://esapubs.org/archive/ecol/E090/118/), which has a metadata file!) \n",
    "\n",
    "Does it have the metadata we need? (e.g. units for weight)\n",
    "\n",
    "### Question: Is it easy to find the info you need in this file? Do you think it would be easy for a computer to parse/find info in this file?\n",
    "\n",
    "We'll now use Frictionless to add some of the missing metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc538394",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from frictionless import describe # import these modules\n",
    "from pprint import pprint # pretty print\n",
    "\n",
    "# describe is the function that reads in data and automatically infers metadata & a schema\n",
    "resource = describe('combined.csv')\n",
    "# NOTE: during intro, tell them to save this csv in the right place while showing jupyter\n",
    "\n",
    "# resource is Frictionless terminology for 'file'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f888005",
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's look at our resource descriptor\n",
    "pprint(resource)\n",
    "# this is JSON..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76400ac",
   "metadata": {},
   "source": [
    "### Questions:\n",
    "- Look at the resource - what is it?\n",
    "- What metadata has been automatically inferred?\n",
    "- Is there other info that would be helpful to future researchers? let's add more metadata to it - manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2a51d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we'll look at just the schema\n",
    "resource.schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc570652",
   "metadata": {},
   "source": [
    "We can access specific fields from the schema to edit. Let's look at the hindfoot_length field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24d7739",
   "metadata": {},
   "outputs": [],
   "source": [
    "resource.schema.get_field('hindfoot_length')\n",
    "# get_field is one way to access information inside the schema\n",
    "# see more examples here https://framework.frictionlessdata.io/docs/guides/framework/schema-guide#field-management"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9a3c51",
   "metadata": {},
   "source": [
    "What does hindfoot length mean? What are the units? Let's add some metadata here as a description to make this data more reusable in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7344ea68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we can add a description to that field\n",
    "resource.schema.get_field('hindfoot_length').description = \"Hindfoot length measured in millimeters\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b21585",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(resource.schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be1a681",
   "metadata": {},
   "source": [
    "We can also update other aspects of the schema, like missing values or constraints. Here's the full API for reference: https://framework.frictionlessdata.io/docs/references/api-reference#field"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42c8ba5",
   "metadata": {},
   "source": [
    "### On your own\n",
    "\n",
    "What other descriptions should we update? Spend a few minutes updating the description for other columns using the metadata https://esapubs.org/archive/ecol/E090/118/Portal_rodent_metadata.htm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b2aa1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# things that Lilly will manipulate on screen while everyone else works on their own\n",
    "resource.schema.get_field('weight').description = \"The weight in grams\"\n",
    "resource.schema.get_field('plot_type').description = \"Describes the experimental condition\"\n",
    "resource.schema.get_field('species_id').description = \"See table 2 https://esapubs.org/archive/ecol/E090/118/Portal_rodent_metadata.htm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145c6d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(resource.schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f4b7b8",
   "metadata": {},
   "source": [
    "(Question for helpers to discuss before the workshop: Should we put people in breakout rooms to work together or just give people like 7 to 10 min in the main room to work silently?)\n",
    "\n",
    "### Question: \n",
    "Share what you edited (2 - 3 min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927d4040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we'll save the resource descriptor\n",
    "resource.to_yaml(\"resource.yaml\")\n",
    "# you can also use JSON if you want with '.to_json'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4623a2",
   "metadata": {},
   "source": [
    "Check out the saved YAML file in the Jupyter Notebook Home directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e882d9b",
   "metadata": {},
   "source": [
    "# Extract\n",
    "\n",
    "Now let's look at the Extract function. Extract reads in a data set, and can also manipulate the data in a few ways by forcing it to conform to a schema. To do this, we'll create a new schema in a resource descriptor and then extract the data from that descriptor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc087ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we will create a new descriptor called resource_string\n",
    "# then we will change the schema so the data type for 'plot_id' is a string\n",
    "# then we save this descriptor to a yaml file\n",
    "from frictionless import extract\n",
    "\n",
    "resource_string = describe('combined.csv')\n",
    "resource_string.schema.get_field('plot_id').type = \"string\"\n",
    "resource_string.to_yaml(\"string_resource.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be207ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we will extract (aka read) the data inside the descriptor file\n",
    "data = extract(\"string_resource.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6448ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's take a look at the first few rows of the read-in dataset\n",
    "# what do we see?\n",
    "data[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be027fb",
   "metadata": {},
   "source": [
    "You can see that plot_id is now a string.\n",
    "\n",
    "### Question: \n",
    "So, what are some instances when you might want to do this type of manipulation? (examples: The data type was inferred incorrectly; You could replace missing values; you could read in only a few lines of the data; you can read just the headers; etc). \n",
    "\n",
    "More info: https://framework.frictionlessdata.io/docs/guides/extracting-data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c6b840",
   "metadata": {},
   "source": [
    "DAY 1 DONE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1479b71",
   "metadata": {},
   "source": [
    "# Validate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315cf003",
   "metadata": {},
   "source": [
    "Take some time to talk about data validation: what it means, why it is important.\n",
    "\n",
    "What kinds of things can be validated? content + structure\n",
    "\n",
    "Examples of both..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bba19b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from frictionless import validate\n",
    "\n",
    "# create a report variable to store the validation report \n",
    "report = validate(resource)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1dac99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(report)\n",
    "# look at the scope here to see all the built-in validation checks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f47e55",
   "metadata": {},
   "source": [
    "Let's purposefully create an error now so we can see how the validation report changes.\n",
    "\n",
    "Make a change to the data file (eg remove a value & comma, or duplicate a header) & validate again\n",
    "\n",
    "Note that this time we are using the data file as the input this time, and frictionless is automatically inferring the metadata from that dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf62ad19",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_invalid = validate('combined.csv')\n",
    "# It isn't using the schema we have edited."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7ea0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(report_invalid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99fb24f",
   "metadata": {},
   "source": [
    "### Question: \n",
    "What has changed in the report? Is it what you expected?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a1f37a",
   "metadata": {},
   "source": [
    "We can also create data constraints that limit the *content* of the data.\n",
    "https://specs.frictionlessdata.io/table-schema/#constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f1b423",
   "metadata": {},
   "outputs": [],
   "source": [
    "constrained_resource = describe('combined.csv')\n",
    "constrained_resource.schema.get_field('sex').constraints[\"enum\"] = [\"M\"]\n",
    "# this means that only values of \"M\" are acceptable for the \"sex\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde6f2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save this descriptor\n",
    "constrained_resource.to_yaml(\"constrained_resource.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f67c974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new validation report\n",
    "report = validate(constrained_resource)\n",
    "pprint(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db60762",
   "metadata": {},
   "source": [
    "### On your own\n",
    "\n",
    "What other things can you validate for? Play around with the data and the schema to create validation errors!\n",
    "We won't get into this today, but Frictionless also has a tool for continuous data validation, [Repository](https://repository.frictionlessdata.io/). A use case for Repository is if you host a dataset on GitHub, everytime that you push changes to that dataset, Repository will run validation checks via a GitHub action and will alert you if there are any errors.\n",
    "(e.g. make sure record_id is unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64068a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# another example: record_id must be unique\n",
    "# remember to change a record_id value to be a duplicate in the data file\n",
    "constrained2_resource = describe('combined.csv')\n",
    "constrained2_resource.schema.get_field('record_id').constraints[\"unique\"] = True\n",
    "report = validate(constrained2_resource)\n",
    "pprint(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c62e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bonus example\n",
    "# you can selectively print out parts of the report if you don't want it all\n",
    "# https://framework.frictionlessdata.io/docs/guides/validation-guide#validation-report\n",
    "report = validate(constrained2_resource, pick_errors=['unique-error'])\n",
    "pprint(report.flatten([\"rowPosition\", \"fieldPosition\", \"code\", \"message\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7df2af",
   "metadata": {},
   "source": [
    "### Question: \n",
    "What else did you validate? Share with the group."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f119b133",
   "metadata": {},
   "source": [
    "# Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317b063c",
   "metadata": {},
   "source": [
    "Now we'll look at the Transform function, which transforms (or cleans) the data set and metadata too.\n",
    "https://framework.frictionlessdata.io/docs/guides/transform-guide\n",
    "\n",
    "Let's look at the date columns. Having 3 separate columns for dates is not standard. (What is standard?) Let's combine those columns into a new column to be more standard. We'll keep the original columns (this is a best practice to keep the original columns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25365185",
   "metadata": {},
   "outputs": [],
   "source": [
    "from frictionless import Resource, transform, steps\n",
    "\n",
    "# Define source resource\n",
    "source = 'resource.yaml'\n",
    "\n",
    "# Apply transform steps\n",
    "target = transform(\n",
    "    source,\n",
    "    steps=[\n",
    "        steps.field_add(name=\"date\", type=\"integer\", formula=\"year+'-'+month+'-'+day\"),\n",
    "        steps.field_update(name=\"date\", type=\"date\"),\n",
    "    ],\n",
    ")\n",
    "\n",
    "# the first step creates a new field that has year, month, and day combined\n",
    "# the second step changes the data type from integer to date\n",
    "# (we need to use this order so we can \"add\" the 3 column names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcfe40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check out the new field in the schema\n",
    "pprint(target.schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04cab3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print out some of the data rows to check the new column \n",
    "# note: this file is HUGE, so stop this cell from running forever with the STOP square button on the menu\n",
    "pprint(target.read_rows())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c896f6f",
   "metadata": {},
   "source": [
    "### Question: \n",
    "What are some other things you might want to transform in this dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68d6580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the validity \n",
    "target_report = validate(target)\n",
    "pprint(target_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e453207d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the data to a file called transformed.csv\n",
    "# then we can look at the data file in whole\n",
    "target.write('transformed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2491b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# and we'll save the descriptor of this datafile too\n",
    "target.to_yaml(\"transformed_descriptor.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd366c9f",
   "metadata": {},
   "source": [
    "Now we can package it up!\n",
    "\n",
    "### Question: \n",
    "Why do we want to package it? (note: we will have talked about this during the intro on day 1, so this will be a good reminder). We package it so we could have the metadata, schema + data all together in 1 file! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23592b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from frictionless import Package\n",
    "package = Package(resources=Resource(path='transformed.csv'), descriptor='transformed_descriptor.yaml') \n",
    "# this package contains the data file + the descriptor file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2dc194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's look at the package\n",
    "pprint(package)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde44822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the package\n",
    "package.to_yaml('package.yaml')\n",
    "# package.to_json('package.json') will save as JSON instead"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8e43f2",
   "metadata": {},
   "source": [
    "Now we can publish this machine-readible packaged (contained) information in 1 place."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374db83e",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "To recap, we started with a pretty clean data file that was missing some important metadata. To make the datafile more reusable, we added metadata with Frictionless Describe. Then we saw how we could use Extract to read in data according to a schema. Next, we validated the data set and metadata/schema to check for data content and structure errors. After that, we transformed the data to add a new, standardized date column. And finally, we packed the data and metadata/schema together so we can publish it!\n",
    "\n",
    "### Bonus Example\n",
    "Dr. Katerina Drakoulaki will tell you all about her recent experience using the Frictionless Framework with Byzantine music data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb119e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
